{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b8a697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ADK components imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.tools import AgentTool, FunctionTool, google_search\n",
    "from google.genai import types\n",
    "\n",
    "from google.adk.tools.mcp_tool.mcp_toolset import McpToolset\n",
    "from google.adk.tools.tool_context import ToolContext\n",
    "from google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams\n",
    "from mcp import StdioServerParameters\n",
    "\n",
    "from google.adk.apps.app import App, ResumabilityConfig\n",
    "from google.adk.tools.function_tool import FunctionTool\n",
    "\n",
    "print(\"✅ ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d82a4e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gemini API key setup complete.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv('GOOGLE_API_KEY')\n",
    "print(\"✅ Gemini API key setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e98d794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ HttpRetryOptions Intialized successfully.\n"
     ]
    }
   ],
   "source": [
    "retry_config=types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors\n",
    ")\n",
    "print(\"✅ HttpRetryOptions Intialized successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9e04a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "Query = \"\"\"\n",
    "I want to build an end-to-end customer churn prediction system for an e-commerce company. \n",
    "The system must include data ingestion, EDA, feature engineering, baseline modeling, model evaluation, \n",
    "and a final API for predictions. \n",
    "Constraints: I have only 10 days, I'm working alone, and I can’t use paid cloud services.\n",
    "Create a complete execution plan following the JSON schema.\n",
    "\"\"\"\n",
    "\n",
    "Planner_Instuction = \"\"\"You are PlannerAgent. Your job is to convert any user project goal into a complete, structured execution plan.\n",
    "\n",
    "STRICT RULES:\n",
    "1. DO NOT ask the user for clarifications unless the user explicitly says “ask me questions”.\n",
    "2. If any information is missing, automatically make reasonable assumptions.\n",
    "3. Always output valid JSON ONLY, following the exact schema.\n",
    "4. Tasks must be concrete, actionable, logically ordered, and achievable within the user’s constraints.\n",
    "5. Never repeat the user’s prompt. Never add commentary.\n",
    "\n",
    "OUTPUT SCHEMA:\n",
    "{\n",
    "  \"project_name\": \"<string>\",\n",
    "  \"summary\": \"<brief overview>\",\n",
    "  \"tasks\": [\n",
    "    {\n",
    "      \"id\": \"<unique-id>\",\n",
    "      \"title\": \"<short title>\",\n",
    "      \"description\": \"<1-2 sentence description>\",\n",
    "      \"priority\": <integer 1-5>,\n",
    "      \"effort_hours\": <number or null>,\n",
    "      \"dependencies\": [\"<task-id>\", ...],\n",
    "      \"required_tools\": [\"<tool-name>\", ...],\n",
    "      \"acceptance_criteria\": \"<clear measurable criteria>\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "BEHAVIOR RULES:\n",
    "- Never ask the user for data sources, metrics, schemas, or definitions.\n",
    "- If the user does not provide details, you MUST infer:\n",
    "  • typical data schemas,\n",
    "  • typical tools,\n",
    "  • typical constraints,\n",
    "  • typical domain assumptions.\n",
    "- Plans must contain between 6 and 20 tasks max.\n",
    "- Maintain accurate ordering via dependencies.\n",
    "- Use realistic, compressed timelines when constraints mention short deadlines.\n",
    "- Use generic open-source tools if the user prohibits paid cloud.\n",
    "\n",
    "REFINEMENT MODE:\n",
    "If the user provides feedback like “update this”, “change this part”, or “refine”, \n",
    "you MUST:\n",
    "- Update the existing plan.\n",
    "- Preserve task IDs where possible.\n",
    "- Output updated full plan in the same JSON schema.\n",
    "\n",
    "FAIL-SAFE MODE:\n",
    "If the LLM produces invalid JSON internally:\n",
    "- Regenerate silently.\n",
    "- Final output must always be valid JSON.\n",
    "\n",
    "\"\"\"\n",
    "Ingestion_instruction = \"\"\"\n",
    "You are DataIngestionAgent. Your task is to act as a structured interface for Kaggle datasets by providing a single, complete JSON output.\n",
    "\n",
    "***STRICT EXECUTION PROTOCOL (Follow Sequentially):***\n",
    "1.  **IF** the user's request contains the word **'download'** (or a known misspelling like 'dowload'):\n",
    "    a. **SKIP ALL OTHER STEPS in Protocol 2**.\n",
    "    b. The agent MUST first call **'search_datasets'** to find the dataset's slugs.\n",
    "    c. From the search results, extract the 'owner_slug', 'dataset_slug', and determine the single largest or most appropriate file name (e.g., 'Netflix_User_Ratings.csv' if not specified by the user).\n",
    "    d. Proceed directly to call **'download_dataset(owner_slug, dataset_slug, file_name)'**.\n",
    "    e. Return the final JSON with an acknowledgment/URL in the 'errors' array.\n",
    "\n",
    "2.  **OTHERWISE (Pure Metadata Mode):**\n",
    "    a. **SEARCH:** **ALWAYS** start by calling 'search_datasets' using the user query.\n",
    "    b. **PROCESS:** From the search results, you MUST identify the **SINGLE MOST RELEVANT dataset** and extract its 'owner_slug' and 'dataset_slug'.\n",
    "    c. **CHAINING:** You MUST sequentially call **'get_dataset_info'** and then **'list_dataset_files'** using the extracted slugs.\n",
    "    d. **OUTPUT TRANSFORMATION (CRITICAL):** After all tool calls are complete, you MUST transform the raw data into the JSON OUTPUT SCHEMA.\n",
    "Your job:\n",
    "- Either find and gather metadata for the single most relevant dataset **OR** execute a direct download request.\n",
    "\n",
    "ALLOWED MCP METHODS (Use these EXACT names):\n",
    "1. search_datasets(search: str, sort_by: str = 'DATASET_SORT_BY_RELEVANCE') -> ApiListDatasetsResponse\n",
    "2. get_dataset_info(owner_slug: str, dataset_slug: str) -> ApiDataset\n",
    "3. list_dataset_files(owner_slug: str, dataset_slug: str) -> ApiListDatasetFilesResponse\n",
    "4. download_dataset(owner_slug: str, dataset_slug: str, file_name: str) -> HttpRedirect\n",
    "\n",
    "JSON OUTPUT SCHEMA (Only one dataset object in the array for this process):\n",
    "{\n",
    "  \"datasets\": [\n",
    "    {\n",
    "      \"title\": \"<string>\",\n",
    "      \"dataset_ref\": \"<owner_slug/dataset_slug>\", \n",
    "      \"description\": \"<string or null>\",\n",
    "      \"license_name\": \"<string or null>\",\n",
    "      \"total_bytes\": <int or null>,\n",
    "      \"tags\": [\"tag1\",\"tag2\",...],\n",
    "      \"files\": [\n",
    "        {\n",
    "          \"filename\": \"<string>\",\n",
    "          \"size_bytes\": <int or null>,\n",
    "          \"file_ref\": \"<string>\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"errors\": []\n",
    "}\n",
    "\n",
    "RULES:\n",
    "- **Output JSON only. ABSOLUTELY NO** markdown, no explanations, no commentary, and NO conversational replies.\n",
    "- **For Download Requests:** Set the 'datasets' array to empty (`[]`). Add a success/failure message and any resulting URL/error from the `download_dataset` tool to the 'errors' array.\n",
    "- **For Metadata Requests:** The 'datasets' array must contain the single, fully populated dataset object.\n",
    "- If a tool call fails, continue the process using the available data and place the specific error message in the \"errors\" array.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a189986",
   "metadata": {},
   "source": [
    "## 1. Ingestion Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18533918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > Find a Kaggle dataset about Netflix movie ratings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayush/Documents/AI/Projects/GENAI/Datapilot-AI-Agent/Virtual/lib/python3.12/site-packages/google/adk/tools/mcp_tool/mcp_tool.py:101: UserWarning: [EXPERIMENTAL] BaseAuthenticatedTool: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataIngestion_agent > ```json\n",
      "{\n",
      "  \"datasets\": [\n",
      "    {\n",
      "      \"title\": \"Netflix Movie Ratings\",\n",
      "      \"dataset_ref\": \"evanschreiner/netflix-movie-ratings\",\n",
      "      \"description\": \"**Context**\\nNetflix held the Netflix Prize open competition for the best algorithm to predict user ratings for films. The grand prize was $1,000,000 and was won by BellKor's Pragmatic Chaos team. This is the dataset that was used in that competition.\\n\\nThe purpose of this dataset is to provide ``csv`` files that can be read directly into a Pandas DataFrame. The procedure detailing how these csv files were created can be found in [this](https://www.kaggle.com/code/evanschreiner/cleaning-netflix-data) notebook.\\n\\nThe ``csv`` files are in turn based on data that was first uploaded to Kaggle [here](https://www.kaggle.com/datasets/netflix-inc/netflix-prize-data).\\n\\n**Netflix_User_Ratings.csv**\\n\\nThe first line in this file contains the headers for each column, CustID, Rating, Date, and MovieID, respectively. Each subsequent line contains an individual rating given by a user for a particular movie.\\n* MovieIDs range from 1 to 17700, in ascending order.\\n* CustomerIDs range from 1 to 2649429, with gaps. There are 480189 users.\\n* Ratings are on a five star (integral) scale from 1 to 5.\\n* Dates have the format YYYY-MM-DD.\\n\\n**Movies.csv**\\n\\nThis file contains the mappings from MovieIDs to Movie Titles. The first line is a header line with the following columns: MovieID, ReleaseYear, and MovieTitle. Each subsequent line contains the respective information, sorted in ascending MovieID order.\\n\\n**About the Author**\\n\\nI'm Evan Schreiner, a Computer Science undergrad at the University of Missouri. I am currently also making lessons and resources for students learning Data Science at Washington University in St. Louis. To get in contact with me, check out my LinkedIn page [here](https://www.linkedin.com/in/evan-schreiner/). I'm working with Professor Ron Cytron, and this work received financial support for Responsible Computer Science from [Mozilla](https://www.mozilla.org/en-US/).\\n\\n**Further Research**\\nAfter exploring this dataset, I found that it would be cool to see how I can add genre information to make my models more accurate. I found genre information and mapped it to each of the Netflix titles found in this dataset [here](https://www.kaggle.com/datasets/evanschreiner/genres)! If you'd like to see how I did this, check out [this notebook](https://www.kaggle.com/code/evanschreiner/fitting-imdb-genres-to-netflix-titles/notebook).\",\n",
      "      \"license_name\": \"Unknown\",\n",
      "      \"total_bytes\": 2711598400,\n",
      "      \"tags\": [\n",
      "        \"movies and tv shows\",\n",
      "        \"universities and colleges\",\n",
      "        \"retail and shopping\"\n",
      "      ],\n",
      "      \"files\": [\n",
      "        {\n",
      "          \"filename\": \"Netflix_User_Ratings.csv\",\n",
      "          \"size_bytes\": 2711021200,\n",
      "          \"file_ref\": \"evanschreiner/netflix-movie-ratings/Netflix_User_Ratings.csv\"\n",
      "        },\n",
      "        {\n",
      "          \"filename\": \"movies.csv\",\n",
      "          \"size_bytes\": 577200,\n",
      "          \"file_ref\": \"evanschreiner/netflix-movie-ratings/movies.csv\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"errors\": []\n",
      "}\n",
      "```\n",
      "[Event(model_version='gemini-2.5-flash', content=Content(\n",
      "  parts=[\n",
      "    Part(\n",
      "      function_call=FunctionCall(\n",
      "        args={\n",
      "          'request': {\n",
      "            'search': 'Netflix movie ratings'\n",
      "          }\n",
      "        },\n",
      "        id='adk-9f4988dd-3419-4317-9439-b66b9faebdda',\n",
      "        name='search_datasets'\n",
      "      ),\n",
      "      thought_signature=b\"\\n\\x82\\x05\\x01\\xd1\\xed\\x8ao}iC\\xa6\\xe8\\x06\\x07\\xe6\\x0c\\x0cl\\x8e6\\x02{\\xcbF\\xcd\\xfd\\x04\\x86yX\\xc7l\\\\Y\\x15\\x9a~Z*\\x88\\xfb\\x94\\xaf\\xbf'\\xc7\\x0f\\x07\\xf7\\xc1\\x06\\xfe;\\xd0\\x18\\x0e\\x80\\x93-U/\\xc0u\\xd9\\x15I\\x92WU\\xe4\\x0cp\\xcf\\xfdI\\x9f\\xc3\\xd7\\xf1\\x8d\\xaa,\\xca$*:\\xf4\\xc4o\\xdaW\\xc6\\x85\\xd3\\xa5\\xe5...'\n",
      "    ),\n",
      "  ],\n",
      "  role='model'\n",
      "), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=<FinishReason.STOP: 'STOP'>, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  candidates_token_count=21,\n",
      "  prompt_token_count=2146,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=2146\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=144,\n",
      "  total_token_count=2311\n",
      "), live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-bac323f0-270e-45c2-a806-5f86132e7a77', author='DataIngestion_agent', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=set(), branch=None, id='980a1ff3-3bc6-46a4-bd8d-9ef5b146dc5a', timestamp=1763572352.262614), Event(model_version=None, content=Content(\n",
      "  parts=[\n",
      "    Part(\n",
      "      function_response=FunctionResponse(\n",
      "        id='adk-9f4988dd-3419-4317-9439-b66b9faebdda',\n",
      "        name='search_datasets',\n",
      "        response={\n",
      "          'content': [\n",
      "            {<... 2 items at Max depth ...>},\n",
      "          ],\n",
      "          'isError': False\n",
      "        }\n",
      "      )\n",
      "    ),\n",
      "  ],\n",
      "  role='user'\n",
      "), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=None, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=None, live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-bac323f0-270e-45c2-a806-5f86132e7a77', author='DataIngestion_agent', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=None, branch=None, id='1644f9ed-f535-4f41-ad0d-9f80d02e3065', timestamp=1763572356.101702), Event(model_version='gemini-2.5-flash', content=Content(\n",
      "  parts=[\n",
      "    Part(\n",
      "      function_call=FunctionCall(\n",
      "        args={\n",
      "          'request': {\n",
      "            'datasetSlug': 'netflix-movie-ratings',\n",
      "            'ownerSlug': 'evanschreiner'\n",
      "          }\n",
      "        },\n",
      "        id='adk-33152e65-275c-4810-8b87-76fbce0ea805',\n",
      "        name='get_dataset_info'\n",
      "      ),\n",
      "      thought_signature=b'\\n\\xd8\\x04\\x01\\xd1\\xed\\x8ao\\xcf\\xbd\\xaba\\x10\\xa67\\x98u\\xeb\\xfd\\x19k\\x0b\\xe0b\\x01\\x10\\x92D\\x03+h\\x1e\\xd4\\xf7\\x0e\\xb5\\x07\\xa54\\xd6\\xae\\x7f\\xb7%\\x00\\xfc\\x0c\\xaa\\x12\\xb3\\x10\\xa8\\xf6\\xdf\\x99\\xc7\\xd7\\xa5`K6&7\\x07\\xeb\\xbeIT\\xf7G\\x1b\"\\x87\\xe1K<+\"\\xd5\\xe5\\x06\\xbf\\xfa\\nL\\xb63\\xd8?x\\x10\\xda\\xd2\\x8b\\xb0\\x8a\\x1e...'\n",
      "    ),\n",
      "  ],\n",
      "  role='model'\n",
      "), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=<FinishReason.STOP: 'STOP'>, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  candidates_token_count=36,\n",
      "  prompt_token_count=21084,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=21084\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=157,\n",
      "  total_token_count=21277\n",
      "), live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-bac323f0-270e-45c2-a806-5f86132e7a77', author='DataIngestion_agent', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=set(), branch=None, id='82d4f5ca-c94f-4aa3-bbf5-d36b1fa4d09c', timestamp=1763572356.60194), Event(model_version=None, content=Content(\n",
      "  parts=[\n",
      "    Part(\n",
      "      function_response=FunctionResponse(\n",
      "        id='adk-33152e65-275c-4810-8b87-76fbce0ea805',\n",
      "        name='get_dataset_info',\n",
      "        response={\n",
      "          'content': [\n",
      "            {<... 2 items at Max depth ...>},\n",
      "          ],\n",
      "          'isError': False\n",
      "        }\n",
      "      )\n",
      "    ),\n",
      "  ],\n",
      "  role='user'\n",
      "), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=None, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=None, live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-bac323f0-270e-45c2-a806-5f86132e7a77', author='DataIngestion_agent', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=None, branch=None, id='52bbef90-b2f6-43dd-bcd5-9fc7c60f49c8', timestamp=1763572361.299891), Event(model_version='gemini-2.5-flash', content=Content(\n",
      "  parts=[\n",
      "    Part(\n",
      "      function_call=FunctionCall(\n",
      "        args={\n",
      "          'request': {\n",
      "            'datasetSlug': 'netflix-movie-ratings',\n",
      "            'ownerSlug': 'evanschreiner'\n",
      "          }\n",
      "        },\n",
      "        id='adk-a802334c-cedc-4ec9-bf35-5c076097abe5',\n",
      "        name='list_dataset_files'\n",
      "      ),\n",
      "      thought_signature=b'\\n\\x99\\x02\\x01\\xd1\\xed\\x8ao\\xc8\\xa8\\xb3>\\x1c\\xdc\\x10\\x9d\\xda\\xa6\\xaf\\xe4\\xb4\\x16-ob\\xe3z|\\x9a\\xe0\\x86*eO|\\xa4\\xa3\\xcaal\\x1b\\xa6\\xeeA\\x0fF \\x1d\\xbf{\\xe0.\\x8c`6}\\xf3\\xce\\xf6\\x8d\\x0b\\xe9K\\xcaL\\x1c-l1x\\x0c\\xb1\\x0eL\\xea\\xd2X\\xb84\\xeey\\xbc2v\\x8e*\\x07CC2)\\xe4\\x00,\\x07\\xa5\\xbc...'\n",
      "    ),\n",
      "  ],\n",
      "  role='model'\n",
      "), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=<FinishReason.STOP: 'STOP'>, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  cache_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=20812\n",
      "    ),\n",
      "  ],\n",
      "  cached_content_token_count=20812,\n",
      "  candidates_token_count=36,\n",
      "  prompt_token_count=22619,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=22619\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=70,\n",
      "  total_token_count=22725\n",
      "), live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-bac323f0-270e-45c2-a806-5f86132e7a77', author='DataIngestion_agent', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=set(), branch=None, id='26c0aeab-c174-4c79-b8a8-863bc52e77c0', timestamp=1763572361.744389), Event(model_version=None, content=Content(\n",
      "  parts=[\n",
      "    Part(\n",
      "      function_response=FunctionResponse(\n",
      "        id='adk-a802334c-cedc-4ec9-bf35-5c076097abe5',\n",
      "        name='list_dataset_files',\n",
      "        response={\n",
      "          'content': [\n",
      "            {<... 2 items at Max depth ...>},\n",
      "          ],\n",
      "          'isError': False\n",
      "        }\n",
      "      )\n",
      "    ),\n",
      "  ],\n",
      "  role='user'\n",
      "), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=None, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=None, live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-bac323f0-270e-45c2-a806-5f86132e7a77', author='DataIngestion_agent', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=None, branch=None, id='0848b677-9d40-4c99-b7ba-4516e4ba0d9e', timestamp=1763572365.865311), Event(model_version='gemini-2.5-flash', content=Content(\n",
      "  parts=[\n",
      "    Part(\n",
      "      text=\"\"\"```json\n",
      "{\n",
      "  \"datasets\": [\n",
      "    {\n",
      "      \"title\": \"Netflix Movie Ratings\",\n",
      "      \"dataset_ref\": \"evanschreiner/netflix-movie-ratings\",\n",
      "      \"description\": \"**Context**\\nNetflix held the Netflix Prize open competition for the best algorithm to predict user ratings for films. The grand prize was $1,000,000 and was won by BellKor's Pragmatic Chaos team. This is the dataset that was used in that competition.\\n\\nThe purpose of this dataset is to provide ``csv`` files that can be read directly into a Pandas DataFrame. The procedure detailing how these csv files were created can be found in [this](https://www.kaggle.com/code/evanschreiner/cleaning-netflix-data) notebook.\\n\\nThe ``csv`` files are in turn based on data that was first uploaded to Kaggle [here](https://www.kaggle.com/datasets/netflix-inc/netflix-prize-data).\\n\\n**Netflix_User_Ratings.csv**\\n\\nThe first line in this file contains the headers for each column, CustID, Rating, Date, and MovieID, respectively. Each subsequent line contains an individual rating given by a user for a particular movie.\\n* MovieIDs range from 1 to 17700, in ascending order.\\n* CustomerIDs range from 1 to 2649429, with gaps. There are 480189 users.\\n* Ratings are on a five star (integral) scale from 1 to 5.\\n* Dates have the format YYYY-MM-DD.\\n\\n**Movies.csv**\\n\\nThis file contains the mappings from MovieIDs to Movie Titles. The first line is a header line with the following columns: MovieID, ReleaseYear, and MovieTitle. Each subsequent line contains the respective information, sorted in ascending MovieID order.\\n\\n**About the Author**\\n\\nI'm Evan Schreiner, a Computer Science undergrad at the University of Missouri. I am currently also making lessons and resources for students learning Data Science at Washington University in St. Louis. To get in contact with me, check out my LinkedIn page [here](https://www.linkedin.com/in/evan-schreiner/). I'm working with Professor Ron Cytron, and this work received financial support for Responsible Computer Science from [Mozilla](https://www.mozilla.org/en-US/).\\n\\n**Further Research**\\nAfter exploring this dataset, I found that it would be cool to see how I can add genre information to make my models more accurate. I found genre information and mapped it to each of the Netflix titles found in this dataset [here](https://www.kaggle.com/datasets/evanschreiner/genres)! If you'd like to see how I did this, check out [this notebook](https://www.kaggle.com/code/evanschreiner/fitting-imdb-genres-to-netflix-titles/notebook).\",\n",
      "      \"license_name\": \"Unknown\",\n",
      "      \"total_bytes\": 2711598400,\n",
      "      \"tags\": [\n",
      "        \"movies and tv shows\",\n",
      "        \"universities and colleges\",\n",
      "        \"retail and shopping\"\n",
      "      ],\n",
      "      \"files\": [\n",
      "        {\n",
      "          \"filename\": \"Netflix_User_Ratings.csv\",\n",
      "          \"size_bytes\": 2711021200,\n",
      "          \"file_ref\": \"evanschreiner/netflix-movie-ratings/Netflix_User_Ratings.csv\"\n",
      "        },\n",
      "        {\n",
      "          \"filename\": \"movies.csv\",\n",
      "          \"size_bytes\": 577200,\n",
      "          \"file_ref\": \"evanschreiner/netflix-movie-ratings/movies.csv\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"errors\": []\n",
      "}\n",
      "```\"\"\",\n",
      "      thought_signature=b'\\n\\x9e\\x1a\\x01\\xd1\\xed\\x8aoC\\x90\\xddJ\\xb6,\\xe8\\xc7S\\xcd\\xf3\\xe4W\\xde|\\x13\\xc0\\x1e\\r\\xf7\\x12\\xfcV\\xc4k\\xef\\x0f&/\\xa4O\\tR\\x98\\xc6\\x87@d\\xf9\\xe3@\\x12\\xaf\\xe2|\\xbe\\xceW\\xbc\\x0f\\xb7\\x9a\\xb6\\x00\\xb83(<`\\x0b?\\xfa\\x08q\\x91kzf8\\xb7\\xde(\\x1d\\xec\\xef\\xfe\\xdb\\x90@\\xef\\x9f\\x1c\\xfc\\x1a\\xdf-\\x037\\xb3...'\n",
      "    ),\n",
      "  ],\n",
      "  role='model'\n",
      "), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=<FinishReason.STOP: 'STOP'>, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  cache_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=21732\n",
      "    ),\n",
      "  ],\n",
      "  cached_content_token_count=21732,\n",
      "  candidates_token_count=862,\n",
      "  prompt_token_count=22840,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=22840\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=894,\n",
      "  total_token_count=24596\n",
      "), live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=CitationMetadata(\n",
      "  citations=[\n",
      "    Citation(\n",
      "      end_index=1910,\n",
      "      license='',\n",
      "      start_index=1668,\n",
      "      uri='https://www.kaggle.com/datasets/evanschreiner/netflix-movie-ratings'\n",
      "    ),\n",
      "    Citation(\n",
      "      end_index=2200,\n",
      "      license='',\n",
      "      start_index=1946,\n",
      "      uri='https://www.kaggle.com/datasets/evanschreiner/netflix-movie-ratings'\n",
      "    ),\n",
      "    Citation(\n",
      "      end_index=2669,\n",
      "      license='',\n",
      "      start_index=2446,\n",
      "      uri='https://www.kaggle.com/datasets/evanschreiner/netflix-movie-ratings'\n",
      "    ),\n",
      "    Citation(\n",
      "      end_index=4909,\n",
      "      license='',\n",
      "      start_index=4667,\n",
      "      uri='https://www.kaggle.com/datasets/evanschreiner/netflix-movie-ratings'\n",
      "    ),\n",
      "    Citation(\n",
      "      end_index=5199,\n",
      "      license='',\n",
      "      start_index=4945,\n",
      "      uri='https://www.kaggle.com/datasets/evanschreiner/netflix-movie-ratings'\n",
      "    ),\n",
      "    <... 1 more items ...>,\n",
      "  ]\n",
      "), invocation_id='e-bac323f0-270e-45c2-a806-5f86132e7a77', author='DataIngestion_agent', actions=EventActions(skip_summarization=None, state_delta={'Dataset_files': '```json\\n{\\n  \"datasets\": [\\n    {\\n      \"title\": \"Netflix Movie Ratings\",\\n      \"dataset_ref\": \"evanschreiner/netflix-movie-ratings\",\\n      \"description\": \"**Context**\\\\nNetflix held the Netflix Prize open competition for the best algorithm to predict user ratings for films. The grand prize was $1,000,000 and was won by BellKor\\'s Pragmatic Chaos team. This is the dataset that was used in that competition.\\\\n\\\\nThe purpose of this dataset is to provide ``csv`` files that can be read directly into a Pandas DataFrame. The procedure detailing how these csv files were created can be found in [this](https://www.kaggle.com/code/evanschreiner/cleaning-netflix-data) notebook.\\\\n\\\\nThe ``csv`` files are in turn based on data that was first uploaded to Kaggle [here](https://www.kaggle.com/datasets/netflix-inc/netflix-prize-data).\\\\n\\\\n**Netflix_User_Ratings.csv**\\\\n\\\\nThe first line in this file contains the headers for each column, CustID, Rating, Date, and MovieID, respectively. Each subsequent line contains an individual rating given by a user for a particular movie.\\\\n* MovieIDs range from 1 to 17700, in ascending order.\\\\n* CustomerIDs range from 1 to 2649429, with gaps. There are 480189 users.\\\\n* Ratings are on a five star (integral) scale from 1 to 5.\\\\n* Dates have the format YYYY-MM-DD.\\\\n\\\\n**Movies.csv**\\\\n\\\\nThis file contains the mappings from MovieIDs to Movie Titles. The first line is a header line with the following columns: MovieID, ReleaseYear, and MovieTitle. Each subsequent line contains the respective information, sorted in ascending MovieID order.\\\\n\\\\n**About the Author**\\\\n\\\\nI\\'m Evan Schreiner, a Computer Science undergrad at the University of Missouri. I am currently also making lessons and resources for students learning Data Science at Washington University in St. Louis. To get in contact with me, check out my LinkedIn page [here](https://www.linkedin.com/in/evan-schreiner/). I\\'m working with Professor Ron Cytron, and this work received financial support for Responsible Computer Science from [Mozilla](https://www.mozilla.org/en-US/).\\\\n\\\\n**Further Research**\\\\nAfter exploring this dataset, I found that it would be cool to see how I can add genre information to make my models more accurate. I found genre information and mapped it to each of the Netflix titles found in this dataset [here](https://www.kaggle.com/datasets/evanschreiner/genres)! If you\\'d like to see how I did this, check out [this notebook](https://www.kaggle.com/code/evanschreiner/fitting-imdb-genres-to-netflix-titles/notebook).\",\\n      \"license_name\": \"Unknown\",\\n      \"total_bytes\": 2711598400,\\n      \"tags\": [\\n        \"movies and tv shows\",\\n        \"universities and colleges\",\\n        \"retail and shopping\"\\n      ],\\n      \"files\": [\\n        {\\n          \"filename\": \"Netflix_User_Ratings.csv\",\\n          \"size_bytes\": 2711021200,\\n          \"file_ref\": \"evanschreiner/netflix-movie-ratings/Netflix_User_Ratings.csv\"\\n        },\\n        {\\n          \"filename\": \"movies.csv\",\\n          \"size_bytes\": 577200,\\n          \"file_ref\": \"evanschreiner/netflix-movie-ratings/movies.csv\"\\n        }\\n      ]\\n    }\\n  ],\\n  \"errors\": []\\n}\\n```'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=None, branch=None, id='8320eefa-976f-40fe-9370-59ca6aa15a86', timestamp=1763572366.303362)]\n",
      "✅ Ingest_agent created.\n"
     ]
    }
   ],
   "source": [
    "os.environ['KAGGLE_USERNAME'] = \"ayushvishwakarma14\"\n",
    "os.environ['KAGGLE_KEY'] = \"8c48a80c1bea8e54c6f00a1ab1963608\"\n",
    "\n",
    "# Data Ingestion Mcp Agent\n",
    "mcp_kaggle_server = McpToolset(\n",
    "    connection_params=StdioConnectionParams(\n",
    "        server_params=StdioServerParameters(\n",
    "            command='npx',\n",
    "            args=[\n",
    "                '-y',\n",
    "                'mcp-remote',\n",
    "                'https://www.kaggle.com/mcp'\n",
    "            ]\n",
    "        ),\n",
    "        timeout=60,\n",
    "    ),\n",
    "    tool_filter=[\n",
    "        \"search_datasets\", \n",
    "        \"get_dataset_info\", \n",
    "        \"list_dataset_files\",\n",
    "        \"download_dataset\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Data Ingestion Agent: Its job is to find the dataset and its info from kaggle mcp\n",
    "ingest_agent = Agent(\n",
    "    name=\"DataIngestion_agent\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    instruction=Ingestion_instruction,\n",
    "    tools=[mcp_kaggle_server],\n",
    "    output_key=\"Dataset_files\", \n",
    ")\n",
    "\n",
    "\n",
    "async def run_ingestion():\n",
    "    \"\"\"Defines the async context for running the agent.\"\"\"\n",
    "    runner = InMemoryRunner(agent = ingest_agent)\n",
    "    response = await runner.run_debug(\"\"\"Find a Kaggle dataset about Netflix movie ratings.\"\"\")\n",
    "    print(response)\n",
    "\n",
    "await run_ingestion()\n",
    "\n",
    "print(\"✅ Ingest_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc892f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
